2025-06-04 00:59:39,743	INFO worker.py:1564 -- Connecting to existing Ray cluster at address: 30.207.96.23:6379...
2025-06-04 00:59:39,750	INFO worker.py:1740 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(main_task pid=712439)[0m /jizhicfs/hymiezhao/ml/reasoning/LUFFY/luffy/verl/verl/utils/tokenizer.py:29: UserWarning: tokenizer.pad_token_id is None. Now set to 128001
[36m(main_task pid=712439)[0m   warnings.warn(f'tokenizer.pad_token_id is None. Now set to {tokenizer.eos_token_id}')
[36m(main_task pid=712439)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=712439)[0m No module named 'vllm._version'
[36m(main_task pid=712439)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=639163, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=639163, ip=30.207.98.85)[0m No module named 'vllm._version'
[36m(pid=639163, ip=30.207.98.85)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=639358, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=639358, ip=30.207.98.85)[0m No module named 'vllm._version'
[36m(pid=639358, ip=30.207.98.85)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/ml/reasoning/LUFFY/luffy/verl/verl/utils/tokenizer.py:29: UserWarning: tokenizer.pad_token_id is None. Now set to 128001
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m   warnings.warn(f'tokenizer.pad_token_id is None. Now set to {tokenizer.eos_token_id}')
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.80it/s]
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.70it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.60it/s]
[36m(pid=712863)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 10x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=712863)[0m No module named 'vllm._version'[32m [repeated 10x across cluster][0m
[36m(pid=712863)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 10x across cluster][0m
[36m(WorkerDict pid=712863)[0m /jizhicfs/hymiezhao/ml/reasoning/LUFFY/luffy/verl/verl/utils/tokenizer.py:29: UserWarning: tokenizer.pad_token_id is None. Now set to 128001[32m [repeated 10x across cluster][0m
[36m(WorkerDict pid=712863)[0m   warnings.warn(f'tokenizer.pad_token_id is None. Now set to {tokenizer.eos_token_id}')[32m [repeated 10x across cluster][0m
[36m(WorkerDict pid=712867)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=712867)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 12x across cluster][0m
[36m(WorkerDict pid=712865)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712865)[0m Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.17it/s][32m [repeated 38x across cluster][0m
[36m(WorkerDict pid=712864)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.35it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.28it/s][32m [repeated 14x across cluster][0m
[36m(pid=712864)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 4x across cluster][0m
[36m(pid=712864)[0m No module named 'vllm._version'[32m [repeated 4x across cluster][0m
[36m(pid=712864)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=712865)[0m /jizhicfs/hymiezhao/ml/reasoning/LUFFY/luffy/verl/verl/utils/tokenizer.py:29: UserWarning: tokenizer.pad_token_id is None. Now set to 128001[32m [repeated 5x across cluster][0m
[36m(WorkerDict pid=712865)[0m   warnings.warn(f'tokenizer.pad_token_id is None. Now set to {tokenizer.eos_token_id}')[32m [repeated 5x across cluster][0m
[36m(WorkerDict pid=712866)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=712866)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=712866)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.40s/it][32m [repeated 8x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.30s/it]
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  3.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.30s/it]
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m   @torch.library.impl_abstract("xformers_flash::flash_fwd")
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m   @torch.library.impl_abstract("xformers_flash::flash_bwd")
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m   @torch.library.impl_abstract("xformers_flash::flash_fwd")[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=712861)[0m   warnings.warn(
[36m(WorkerDict pid=712867)[0m   @torch.library.impl_abstract("xformers_flash::flash_bwd")[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.[32m [repeated 15x across cluster][0m
[36m(main_task pid=712439)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(WorkerDict pid=712865)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712865)[0m   warnings.warn([32m [repeated 15x across cluster][0m
[36m(main_task pid=712439)[0m wandb: Currently logged in as: maluqaq (theroadqaq). Use `wandb login --relogin` to force relogin
[36m(main_task pid=712439)[0m wandb: Tracking run with wandb version 0.19.1
[36m(main_task pid=712439)[0m wandb: Run data is saved locally in /jizhicfs/hymiezhao/ml/reasoning/LUFFY/wandb/run-20250604_010342-exrj73zg
[36m(main_task pid=712439)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=712439)[0m wandb: Syncing run llama_8_on_policy
[36m(main_task pid=712439)[0m wandb: ⭐️ View project at https://wandb.ai/theroadqaq/rl-sft
[36m(main_task pid=712439)[0m wandb: 🚀 View run at https://wandb.ai/theroadqaq/rl-sft/runs/exrj73zg
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.[32m [repeated 9x across cluster][0m
[36m(WorkerDict pid=712866)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined][32m [repeated 9x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   warnings.warn(
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
[36m(WorkerDict pid=712864)[0m /jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m   warnings.warn([32m [repeated 15x across cluster][0m
Traceback (most recent call last):
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/jizhicfs/hymiezhao/ml/reasoning/LUFFY/luffy/verl/verl/mix_src/main_mix_ppo.py", line 256, in <module>
    main()
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/jizhicfs/hymiezhao/ml/reasoning/LUFFY/luffy/verl/verl/mix_src/main_mix_ppo.py", line 143, in main
    ray.get(main_task.remote(config))
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/ray/_private/worker.py", line 2623, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/ray/_private/worker.py", line 840, in get_objects
    data_metadata_pairs = self.core_worker.get_objects(
  File "python/ray/_raylet.pyx", line 3481, in ray._raylet.CoreWorker.get_objects
  File "python/ray/_raylet.pyx", line 571, in ray._raylet.check_status
KeyboardInterrupt
Exception ignored in atexit callback: <function shutdown at 0x7f1186974c10>
Traceback (most recent call last):
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/jizhicfs/hymiezhao/miniconda3/envs/LUFFY/lib/python3.10/site-packages/ray/_private/worker.py", line 1813, in shutdown
    time.sleep(0.5)
KeyboardInterrupt: 
[36m(main_task pid=712439)[0m {'actor_rollout_ref': {'actor': {'adaptive_temperature_clip': -1,
[36m(main_task pid=712439)[0m                                  'adaptive_temperature_target_entropy': 1.0,
[36m(main_task pid=712439)[0m                                  'all_max_clip': -1,
[36m(main_task pid=712439)[0m                                  'alpha_lr': 0.01,
[36m(main_task pid=712439)[0m                                  'clip_ratio': 0.2,
[36m(main_task pid=712439)[0m                                  'clip_upper_bound': 1.0,
[36m(main_task pid=712439)[0m                                  'debug': False,
[36m(main_task pid=712439)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=712439)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=712439)[0m                                                  'grad_offload': False,
[36m(main_task pid=712439)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=712439)[0m                                                  'param_offload': False,
[36m(main_task pid=712439)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=712439)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=712439)[0m                                  'kl_loss_coef': 0.0,
[36m(main_task pid=712439)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=712439)[0m                                  'loss_remove_clip': False,
[36m(main_task pid=712439)[0m                                  'loss_remove_token_mean': True,
[36m(main_task pid=712439)[0m                                  'off_policy_cliprange': 0.2,
[36m(main_task pid=712439)[0m                                  'off_policy_loss_impl': 'token',
[36m(main_task pid=712439)[0m                                  'off_policy_max_clip': -1,
[36m(main_task pid=712439)[0m                                  'off_policy_min_clip': -1,
[36m(main_task pid=712439)[0m                                  'off_policy_normalize': False,
[36m(main_task pid=712439)[0m                                  'off_policy_reshape': 'no_reshape',
[36m(main_task pid=712439)[0m                                  'off_policy_reshape_pow_exp': 0.5,
[36m(main_task pid=712439)[0m                                  'off_policy_reshape_weight': 0.1,
[36m(main_task pid=712439)[0m                                  'on_policy_reshape': 'no_reshape',
[36m(main_task pid=712439)[0m                                  'on_policy_reshape_pow_exp': 0.5,
[36m(main_task pid=712439)[0m                                  'on_policy_reshape_weight': 0.1,
[36m(main_task pid=712439)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=712439)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=712439)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=712439)[0m                                            'total_training_steps': -1,
[36m(main_task pid=712439)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=712439)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=712439)[0m                                  'ppo_kl_loss_coef': 0.01,
[36m(main_task pid=712439)[0m                                  'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=712439)[0m                                  'ppo_micro_batch_size': 64,
[36m(main_task pid=712439)[0m                                  'ppo_mini_batch_size': 64,
[36m(main_task pid=712439)[0m                                  'sft_prefix_reward_weight': 1.0,
[36m(main_task pid=712439)[0m                                  'shuffle': False,
[36m(main_task pid=712439)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=712439)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=712439)[0m                                  'use_adaptive_temperature': False,
[36m(main_task pid=712439)[0m                                  'use_adaptive_temperature_fixed': False,
[36m(main_task pid=712439)[0m                                  'use_dynamic_bsz': True,
[36m(main_task pid=712439)[0m                                  'use_kl_loss': False,
[36m(main_task pid=712439)[0m                                  'use_off_policy_clip': False,
[36m(main_task pid=712439)[0m                                  'use_off_policy_loss': True,
[36m(main_task pid=712439)[0m                                  'use_off_policy_probs': False,
[36m(main_task pid=712439)[0m                                  'use_ppo_kl_loss': False,
[36m(main_task pid=712439)[0m                                  'use_sft_prefix_reward': False,
[36m(main_task pid=712439)[0m                                  'use_sft_reward': False,
[36m(main_task pid=712439)[0m                                  'use_target_lst': False},
[36m(main_task pid=712439)[0m                        'hybrid_engine': True,
[36m(main_task pid=712439)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=712439)[0m                                  'external_lib': None,
[36m(main_task pid=712439)[0m                                  'override_config': {},
[36m(main_task pid=712439)[0m                                  'path': '/jizhicfs/hymiezhao/models/Meta-Llama-3.1-8B',
[36m(main_task pid=712439)[0m                                  'use_remove_padding': True},
[36m(main_task pid=712439)[0m                        'ref': {'fsdp_config': {'param_offload': True,
[36m(main_task pid=712439)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=712439)[0m                                'log_prob_max_token_len_per_gpu': 32768,
[36m(main_task pid=712439)[0m                                'log_prob_micro_batch_size': 128,
[36m(main_task pid=712439)[0m                                'log_prob_use_dynamic_bsz': True,
[36m(main_task pid=712439)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=712439)[0m                                'use_ref': False},
[36m(main_task pid=712439)[0m                        'rollout': {'do_sample': True,
[36m(main_task pid=712439)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=712439)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=712439)[0m                                    'enforce_eager': True,
[36m(main_task pid=712439)[0m                                    'free_cache_engine': True,
[36m(main_task pid=712439)[0m                                    'gpu_memory_utilization': 0.8,
[36m(main_task pid=712439)[0m                                    'ignore_eos': False,
[36m(main_task pid=712439)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=712439)[0m                                    'log_prob_max_token_len_per_gpu': 32768,
[36m(main_task pid=712439)[0m                                    'log_prob_micro_batch_size': 128,
[36m(main_task pid=712439)[0m                                    'log_prob_use_dynamic_bsz': True,
[36m(main_task pid=712439)[0m                                    'max_num_batched_tokens': 8192,
[36m(main_task pid=712439)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=712439)[0m                                    'max_prefix_len': 8192,
[36m(main_task pid=712439)[0m                                    'max_prefix_ratio': 0.0,
[36m(main_task pid=712439)[0m                                    'min_prefix_ratio': 0.0,
[36m(main_task pid=712439)[0m                                    'n': 8,
[36m(main_task pid=712439)[0m                                    'n_prefix': 1,
[36m(main_task pid=712439)[0m                                    'n_val': 1,
[36m(main_task pid=712439)[0m                                    'name': 'vllm',
[36m(main_task pid=712439)[0m                                    'prefix_linear_max_ratio': 0.8,
[36m(main_task pid=712439)[0m                                    'prefix_linear_max_var': 0.1,
[36m(main_task pid=712439)[0m                                    'prefix_reward_strategy': 'all',
[36m(main_task pid=712439)[0m                                    'prefix_reward_weight_alpha': 1.0,
[36m(main_task pid=712439)[0m                                    'prefix_reward_weight_beta': 1.0,
[36m(main_task pid=712439)[0m                                    'prefix_share_across_samples': False,
[36m(main_task pid=712439)[0m                                    'prefix_steps': 1000,
[36m(main_task pid=712439)[0m                                    'prefix_strategy': 'random',
[36m(main_task pid=712439)[0m                                    'prompt_length': 1024,
[36m(main_task pid=712439)[0m                                    'response_length': 8192,
[36m(main_task pid=712439)[0m                                    'temperature': 1.0,
[36m(main_task pid=712439)[0m                                    'tensor_model_parallel_size': 2,
[36m(main_task pid=712439)[0m                                    'top_k': -1,
[36m(main_task pid=712439)[0m                                    'top_p': 1,
[36m(main_task pid=712439)[0m                                    'val_temperature': 0.6}},
[36m(main_task pid=712439)[0m  'algorithm': {'adv_estimator': 'grpo',
[36m(main_task pid=712439)[0m                'gamma': 1.0,
[36m(main_task pid=712439)[0m                'grpo_use_std': False,
[36m(main_task pid=712439)[0m                'kl_ctrl': {'kl_coef': 0.0, 'type': 'fixed'},
[36m(main_task pid=712439)[0m                'kl_penalty': 'kl',
[36m(main_task pid=712439)[0m                'lam': 1.0,
[36m(main_task pid=712439)[0m                'surprisal_base': 0.0},
[36m(main_task pid=712439)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=712439)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=712439)[0m             'forward_micro_batch_size': 64,
[36m(main_task pid=712439)[0m             'grad_clip': 1.0,
[36m(main_task pid=712439)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=712439)[0m                       'external_lib': None,
[36m(main_task pid=712439)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=712439)[0m                                       'grad_offload': False,
[36m(main_task pid=712439)[0m                                       'optimizer_offload': False,
[36m(main_task pid=712439)[0m                                       'param_offload': False,
[36m(main_task pid=712439)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=712439)[0m                       'override_config': {},
[36m(main_task pid=712439)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(main_task pid=712439)[0m                       'tokenizer_path': '/jizhicfs/hymiezhao/models/Meta-Llama-3.1-8B',
[36m(main_task pid=712439)[0m                       'use_remove_padding': False},
[36m(main_task pid=712439)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=712439)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=712439)[0m                       'min_lr_ratio': None,
[36m(main_task pid=712439)[0m                       'total_training_steps': -1,
[36m(main_task pid=712439)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=712439)[0m             'ppo_epochs': 1,
[36m(main_task pid=712439)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=712439)[0m             'ppo_micro_batch_size': 64,
[36m(main_task pid=712439)[0m             'ppo_mini_batch_size': 64,
[36m(main_task pid=712439)[0m             'shuffle': False,
[36m(main_task pid=712439)[0m             'strategy': 'fsdp',
[36m(main_task pid=712439)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=712439)[0m             'use_dynamic_bsz': True},
[36m(main_task pid=712439)[0m  'data': {'accuracy_lower_bound': 0.0,
[36m(main_task pid=712439)[0m           'accuracy_upper_bound': 1.0,
[36m(main_task pid=712439)[0m           'add_tgt_acc_upper_bound': 0.5,
[36m(main_task pid=712439)[0m           'add_tgt_with_acc': False,
[36m(main_task pid=712439)[0m           'disable_truncation_advantage': False,
[36m(main_task pid=712439)[0m           'filter_accuracy': False,
[36m(main_task pid=712439)[0m           'filter_targets': False,
[36m(main_task pid=712439)[0m           'max_prompt_length': 1024,
[36m(main_task pid=712439)[0m           'max_response_length': 8192,
[36m(main_task pid=712439)[0m           'prompt_key': 'prompt',
[36m(main_task pid=712439)[0m           'return_raw_chat': False,
[36m(main_task pid=712439)[0m           'return_raw_input_ids': False,
[36m(main_task pid=712439)[0m           'reward_impl_version': 3,
[36m(main_task pid=712439)[0m           'sample_target_ratio': 1.0,
[36m(main_task pid=712439)[0m           'shuffle': True,
[36m(main_task pid=712439)[0m           'tokenizer': None,
[36m(main_task pid=712439)[0m           'train_batch_size': 128,
[36m(main_task pid=712439)[0m           'train_files': './dataset//llama_openr1.parquet',
[36m(main_task pid=712439)[0m           'val_batch_size': 512,
[36m(main_task pid=712439)[0m           'val_files': './dataset//llama_valid.parquet'},
[36m(main_task pid=712439)[0m  'reward_model': {'enable': False,
[36m(main_task pid=712439)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=712439)[0m                   'max_length': None,
[36m(main_task pid=712439)[0m                   'micro_batch_size': 64,
[36m(main_task pid=712439)[0m                   'model': {'external_lib': None,
[36m(main_task pid=712439)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=712439)[0m                                             'min_num_params': 0,
[36m(main_task pid=712439)[0m                                             'param_offload': False},
[36m(main_task pid=712439)[0m                             'input_tokenizer': '/jizhicfs/hymiezhao/models/Meta-Llama-3.1-8B',
[36m(main_task pid=712439)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=712439)[0m                             'use_remove_padding': False},
[36m(main_task pid=712439)[0m                   'strategy': 'fsdp',
[36m(main_task pid=712439)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=712439)[0m                   'use_dynamic_bsz': True},
[36m(main_task pid=712439)[0m  'trainer': {'acc_rebatch': False,
[36m(main_task pid=712439)[0m              'add_full_target_when_none': False,
[36m(main_task pid=712439)[0m              'critic_warmup': 0,
[36m(main_task pid=712439)[0m              'debug': False,
[36m(main_task pid=712439)[0m              'default_hdfs_dir': None,
[36m(main_task pid=712439)[0m              'default_local_dir': './train_results/rl-sft/llama_8_on_policy',
[36m(main_task pid=712439)[0m              'experiment_name': 'llama_8_on_policy',
[36m(main_task pid=712439)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=712439)[0m              'max_optim_to_keep': 2,
[36m(main_task pid=712439)[0m              'n_gpus_per_node': 8,
[36m(main_task pid=712439)[0m              'nnodes': 2,
[36m(main_task pid=712439)[0m              'project_name': 'rl-sft',
[36m(main_task pid=712439)[0m              'rejection_sample': False,
[36m(main_task pid=712439)[0m              'rejection_sample_multiplier': 2,
[36m(main_task pid=712439)[0m              'resume_from_path': False,
[36m(main_task pid=712439)[0m              'resume_mode': 'auto',
[36m(main_task pid=712439)[0m              'save_freq': -1,
[36m(main_task pid=712439)[0m              'skip_by_step': False,
[36m(main_task pid=712439)[0m              'skip_valid_mask': False,
[36m(main_task pid=712439)[0m              'test_freq': 10,
[36m(main_task pid=712439)[0m              'total_epochs': 3,
[36m(main_task pid=712439)[0m              'total_training_steps': None,
[36m(main_task pid=712439)[0m              'val_before_train': False}}
[36m(main_task pid=712439)[0m original dataset len: 45792
[36m(main_task pid=712439)[0m filter dataset len: 45774
[36m(main_task pid=712439)[0m original dataset len: 2019
[36m(main_task pid=712439)[0m filter dataset len: 2017
[36m(main_task pid=712439)[0m Size of train dataloader: 357
[36m(main_task pid=712439)[0m Size of val dataloader: 1
[36m(main_task pid=712439)[0m Total training steps: 1071
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Model config after override: LlamaConfig {
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "_name_or_path": "/jizhicfs/hymiezhao/models/Meta-Llama-3.1-8B",
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "architectures": [
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m     "LlamaForCausalLM"
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   ],
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "attention_bias": false,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "bos_token_id": 128000,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "eos_token_id": 128001,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "head_dim": 128,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "hidden_size": 4096,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "intermediate_size": 14336,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "max_position_embeddings": 131072,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "mlp_bias": false,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "model_type": "llama",
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "num_attention_heads": 32,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "num_hidden_layers": 32,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "num_key_value_heads": 8,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "pad_token_id": 128001,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "pretraining_tp": 1,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "rms_norm_eps": 1e-05,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "rope_scaling": {
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m     "factor": 8.0,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m     "high_freq_factor": 4.0,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m     "low_freq_factor": 1.0,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m     "original_max_position_embeddings": 8192,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m     "rope_type": "llama3"
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   },
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "rope_theta": 500000.0,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "transformers_version": "4.46.3",
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "use_cache": true,
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m   "vocab_size": 128256
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m }
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m 
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=712860)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7f5b6e08ad40>, transformer_layer_cls={<class 'transformers.models.llama.modeling_llama.LlamaDecoderLayer'>})
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m LlamaForCausalLM contains 8.03B parameters
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m Total steps: 1071, num_warmup_steps: 0
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7f9d5e43ed40>, transformer_layer_cls={<class 'transformers.models.llama.modeling_llama.LlamaDecoderLayer'>})[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Before building vllm rollout, memory allocated (GB): 1.8697071075439453, memory reserved (GB): 15.87890625
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m INFO 06-04 01:02:47 config.py:887] Defaulting to use ray for distributed inference
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m INFO 06-04 01:02:47 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m WARNING 06-04 01:02:47 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Total steps: 1071, num_warmup_steps: 0[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Actor use_remove_padding=True[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m local rank 0
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m INFO 06-04 01:02:48 selector.py:115] Using XFormers backend.
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m INFO 06-04 01:02:57 utils.py:1008] Found nccl from library libnccl.so.2
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m INFO 06-04 01:02:57 pynccl.py:63] vLLM is using nccl==2.20.5
[36m(WorkerDict pid=712867)[0m INFO 06-04 01:02:49 config.py:887] Defaulting to use ray for distributed inference[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m INFO 06-04 01:02:49 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=8192.[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m WARNING 06-04 01:02:49 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m local rank 0[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m INFO 06-04 01:02:50 selector.py:115] Using XFormers backend.[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m INFO 06-04 01:02:58 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7eef547c3a30>, local_subscribe_port=55485, remote_subscribe_port=None)
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m before init cache memory allocated: 10.082285056GB, reserved: 10.166992896GB
[36m(WorkerDict pid=712861)[0m kwargs: {'n': 8, 'logprobs': 1, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=712864)[0m INFO 06-04 01:02:57 utils.py:1008] Found nccl from library libnccl.so.2[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m INFO 06-04 01:02:57 pynccl.py:63] vLLM is using nccl==2.20.5[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m INFO 06-04 01:02:59 selector.py:115] Using XFormers backend.[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m NCCL version 2.20.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=712866)[0m INFO 06-04 01:02:59 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fc11072add0>, local_subscribe_port=36485, remote_subscribe_port=None)[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m after init cache memory allocated: 66.722166272GB, reserved: 66.806874112GB
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m After building vllm rollout, memory allocated (GB): 54.65889501571655, memory reserved (GB): 62.21875
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m After building sharding manager, memory allocated (GB): 54.65889501571655, memory reserved (GB): 62.21875
[36m(main_task pid=712439)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(main_task pid=712439)[0m Checkpoint tracker file does not exist: %s /jizhicfs/hymiezhao/ml/reasoning/LUFFY/./train_results/rl-sft/llama_8_on_policy/latest_checkpointed_iteration.txt
[36m(main_task pid=712439)[0m Training from scratch
[36m(WorkerDict pid=712865)[0m kwargs: {'n': 8, 'logprobs': 1, 'max_tokens': 8192, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(main_task pid=712439)[0m step:1 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:49702.000 - global_seqlen/max:88076.000 - global_seqlen/minmax_diff:38374.000 - global_seqlen/balanced_min:66764.000 - global_seqlen/balanced_max:66765.000 - global_seqlen/mean:66764.875 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.542 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:1.629 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.039 - mfu/actor:0.252 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:933.756 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.016 - on_off_metrics/on_response_length_mean:933.756 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:109.445 - prompt_length/max:371.000 - prompt_length/min:40.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:205.088 - timing_s/old_log_prob:10.945 - timing_s/adv:11.569 - timing_s/update_actor:46.179 - timing_s/step:263.123 - timing_per_token_ms/update_actor:0.043 - timing_per_token_ms/adv:0.011 - timing_per_token_ms/gen:0.214
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:2 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:39510.000 - global_seqlen/max:85865.000 - global_seqlen/minmax_diff:46355.000 - global_seqlen/balanced_min:60199.000 - global_seqlen/balanced_max:60200.000 - global_seqlen/mean:60199.562 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.443 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:2.235 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:-0.000 - actor/grad_norm:0.039 - mfu/actor:0.332 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:840.892 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.010 - on_off_metrics/on_response_length_mean:840.892 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:99.727 - prompt_length/max:236.000 - prompt_length/min:42.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:195.860 - timing_s/old_log_prob:9.304 - timing_s/adv:10.069 - timing_s/update_actor:31.530 - timing_s/step:237.743 - timing_per_token_ms/update_actor:0.033 - timing_per_token_ms/adv:0.010 - timing_per_token_ms/gen:0.227
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712862)[0m MICROBATCH STEP
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:3 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:46268.000 - global_seqlen/max:76280.000 - global_seqlen/minmax_diff:30012.000 - global_seqlen/balanced_min:61516.000 - global_seqlen/balanced_max:61517.000 - global_seqlen/mean:61516.375 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.433 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:2.378 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.043 - mfu/actor:0.341 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:860.115 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.010 - on_off_metrics/on_response_length_mean:860.115 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:101.078 - prompt_length/max:229.000 - prompt_length/min:39.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:191.181 - timing_s/old_log_prob:8.023 - timing_s/adv:8.657 - timing_s/update_actor:31.829 - timing_s/step:231.931 - timing_per_token_ms/update_actor:0.032 - timing_per_token_ms/adv:0.009 - timing_per_token_ms/gen:0.217
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712862)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:4 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:41574.000 - global_seqlen/max:82327.000 - global_seqlen/minmax_diff:40753.000 - global_seqlen/balanced_min:57717.000 - global_seqlen/balanced_max:58058.000 - global_seqlen/mean:57827.188 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.233 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:4.482 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.001 - actor/grad_norm:0.059 - mfu/actor:0.367 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:803.308 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.018 - on_off_metrics/on_response_length_mean:803.308 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:100.242 - prompt_length/max:356.000 - prompt_length/min:40.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:194.241 - timing_s/old_log_prob:8.995 - timing_s/adv:9.650 - timing_s/update_actor:27.882 - timing_s/step:232.046 - timing_per_token_ms/update_actor:0.030 - timing_per_token_ms/adv:0.010 - timing_per_token_ms/gen:0.236
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:5 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:47391.000 - global_seqlen/max:100364.000 - global_seqlen/minmax_diff:52973.000 - global_seqlen/balanced_min:68296.000 - global_seqlen/balanced_max:68297.000 - global_seqlen/mean:68296.188 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.203 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:4.703 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.072 - mfu/actor:0.373 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:961.042 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.031 - on_off_metrics/on_response_length_mean:961.042 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:106.086 - prompt_length/max:379.000 - prompt_length/min:34.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:218.209 - timing_s/old_log_prob:10.194 - timing_s/adv:10.877 - timing_s/update_actor:33.027 - timing_s/step:262.415 - timing_per_token_ms/update_actor:0.030 - timing_per_token_ms/adv:0.010 - timing_per_token_ms/gen:0.222
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:6 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:87445.000 - global_seqlen/max:155063.000 - global_seqlen/minmax_diff:67618.000 - global_seqlen/balanced_min:115760.000 - global_seqlen/balanced_max:115761.000 - global_seqlen/mean:115760.750 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.062 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:7.311 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.004 - actor/grad_norm:0.129 - mfu/actor:0.414 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:1699.355 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.104 - on_off_metrics/on_response_length_mean:1699.355 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:109.406 - prompt_length/max:407.000 - prompt_length/min:38.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:221.095 - timing_s/old_log_prob:14.909 - timing_s/adv:15.769 - timing_s/update_actor:52.556 - timing_s/step:289.652 - timing_per_token_ms/update_actor:0.028 - timing_per_token_ms/adv:0.009 - timing_per_token_ms/gen:0.127
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:7 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:111421.000 - global_seqlen/max:208202.000 - global_seqlen/minmax_diff:96781.000 - global_seqlen/balanced_min:170782.000 - global_seqlen/balanced_max:170783.000 - global_seqlen/mean:170782.688 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.014 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:8.569 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.003 - actor/grad_norm:0.188 - mfu/actor:0.395 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:2565.042 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.171 - on_off_metrics/on_response_length_mean:2565.042 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:103.438 - prompt_length/max:356.000 - prompt_length/min:37.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:272.102 - timing_s/old_log_prob:19.897 - timing_s/adv:21.459 - timing_s/update_actor:82.379 - timing_s/step:376.154 - timing_per_token_ms/update_actor:0.030 - timing_per_token_ms/adv:0.008 - timing_per_token_ms/gen:0.104
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:8 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:91795.000 - global_seqlen/max:194775.000 - global_seqlen/minmax_diff:102980.000 - global_seqlen/balanced_min:150166.000 - global_seqlen/balanced_max:150167.000 - global_seqlen/mean:150166.062 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.008 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:9.221 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.004 - actor/grad_norm:0.160 - mfu/actor:0.385 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:2233.837 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.104 - on_off_metrics/on_response_length_mean:2233.837 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:112.508 - prompt_length/max:318.000 - prompt_length/min:41.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:222.491 - timing_s/old_log_prob:18.446 - timing_s/adv:19.686 - timing_s/update_actor:73.403 - timing_s/step:315.847 - timing_per_token_ms/update_actor:0.031 - timing_per_token_ms/adv:0.008 - timing_per_token_ms/gen:0.097
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:9 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:109353.000 - global_seqlen/max:197283.000 - global_seqlen/minmax_diff:87930.000 - global_seqlen/balanced_min:148802.000 - global_seqlen/balanced_max:148802.000 - global_seqlen/mean:148802.000 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.038 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:9.320 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.004 - actor/grad_norm:0.112 - mfu/actor:0.428 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:2216.789 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.109 - on_off_metrics/on_response_length_mean:2216.789 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:108.242 - prompt_length/max:373.000 - prompt_length/min:48.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:237.351 - timing_s/old_log_prob:18.592 - timing_s/adv:19.838 - timing_s/update_actor:66.070 - timing_s/step:323.519 - timing_per_token_ms/update_actor:0.028 - timing_per_token_ms/adv:0.008 - timing_per_token_ms/gen:0.105
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m Validation: Generation end.
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m Find no current best saved. Best score is set to -inf
[36m(main_task pid=712439)[0m Saving best checkpoint with score 0.0 at ./train_results/rl-sft/llama_8_on_policy/best/actor
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m Saving actor checkpoint to ./train_results/rl-sft/llama_8_on_policy/best/actor
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m [2025-06-04 02:02:37,860] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(main_task pid=712439)[0m step:10 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:206821.000 - global_seqlen/max:330660.000 - global_seqlen/minmax_diff:123839.000 - global_seqlen/balanced_min:281378.000 - global_seqlen/balanced_max:281379.000 - global_seqlen/mean:281378.625 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.002 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:10.323 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.046 - actor/grad_norm:0.207 - mfu/actor:0.452 - actor/lr:0.000 - val/test_score/math:0.000 - val/test_score/minerva:0.000 - val/test_score/olympiad_bench:0.000 - val/test_score/aime:0.000 - val/test_score/amc:0.000 - avg_score:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:4299.025 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.342 - on_off_metrics/on_response_length_mean:4299.025 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:97.516 - prompt_length/max:302.000 - prompt_length/min:40.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:394.170 - timing_s/old_log_prob:30.831 - timing_s/adv:33.056 - timing_s/update_actor:119.743 - timing_s/testing:409.456 - timing_s/step:1034.839 - timing_per_token_ms/update_actor:0.027 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.090
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m 
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:11 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:236435.000 - global_seqlen/max:320124.000 - global_seqlen/minmax_diff:83689.000 - global_seqlen/balanced_min:275635.000 - global_seqlen/balanced_max:275636.000 - global_seqlen/mean:275635.062 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:10.753 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.015 - actor/grad_norm:0.200 - mfu/actor:0.433 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:4204.298 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.305 - on_off_metrics/on_response_length_mean:4204.298 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:102.500 - prompt_length/max:266.000 - prompt_length/min:36.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:362.373 - timing_s/old_log_prob:29.891 - timing_s/adv:32.152 - timing_s/update_actor:121.773 - timing_s/step:516.554 - timing_per_token_ms/update_actor:0.028 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.084
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:12 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:347491.000 - global_seqlen/max:451996.000 - global_seqlen/minmax_diff:104505.000 - global_seqlen/balanced_min:390897.000 - global_seqlen/balanced_max:390898.000 - global_seqlen/mean:390897.375 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.001 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.006 - actor/grad_norm:0.243 - mfu/actor:0.465 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:6000.271 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.660 - on_off_metrics/on_response_length_mean:6000.271 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:107.500 - prompt_length/max:324.000 - prompt_length/min:34.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:476.414 - timing_s/old_log_prob:41.927 - timing_s/adv:45.050 - timing_s/update_actor:165.055 - timing_s/step:686.750 - timing_per_token_ms/update_actor:0.026 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.078
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:13 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:321190.000 - global_seqlen/max:421145.000 - global_seqlen/minmax_diff:99955.000 - global_seqlen/balanced_min:370936.000 - global_seqlen/balanced_max:370937.000 - global_seqlen/mean:370936.062 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.192 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.008 - actor/grad_norm:0.122 - mfu/actor:0.473 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:5704.173 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.606 - on_off_metrics/on_response_length_mean:5704.173 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:91.703 - prompt_length/max:355.000 - prompt_length/min:36.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:456.366 - timing_s/old_log_prob:39.187 - timing_s/adv:42.095 - timing_s/update_actor:153.248 - timing_s/step:651.957 - timing_per_token_ms/update_actor:0.026 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.078
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m 
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:14 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:330927.000 - global_seqlen/max:422604.000 - global_seqlen/minmax_diff:91677.000 - global_seqlen/balanced_min:362384.000 - global_seqlen/balanced_max:362384.000 - global_seqlen/mean:362384.000 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.278 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.004 - actor/grad_norm:0.129 - mfu/actor:0.454 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:5559.203 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.560 - on_off_metrics/on_response_length_mean:5559.203 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:103.047 - prompt_length/max:267.000 - prompt_length/min:40.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:445.894 - timing_s/old_log_prob:38.893 - timing_s/adv:41.708 - timing_s/update_actor:155.837 - timing_s/step:643.709 - timing_per_token_ms/update_actor:0.027 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.078
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712862)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m 
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:15 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:410710.000 - global_seqlen/max:480777.000 - global_seqlen/minmax_diff:70067.000 - global_seqlen/balanced_min:447353.000 - global_seqlen/balanced_max:447353.000 - global_seqlen/mean:447353.000 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.374 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.005 - actor/grad_norm:0.084 - mfu/actor:0.497 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:6888.508 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.757 - on_off_metrics/on_response_length_mean:6888.508 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:101.383 - prompt_length/max:570.000 - prompt_length/min:39.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:513.856 - timing_s/old_log_prob:44.301 - timing_s/adv:47.839 - timing_s/update_actor:176.437 - timing_s/step:738.401 - timing_per_token_ms/update_actor:0.025 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.073
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 03:04:58 scheduler.py:1484] Sequence group 2300 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
[36m(WorkerDict pid=712860)[0m WARNING 06-04 03:05:05 scheduler.py:1484] Sequence group 2301 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 03:05:14 scheduler.py:1484] Sequence group 2301 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 03:05:25 scheduler.py:1484] Sequence group 2301 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 03:05:49 scheduler.py:1484] Sequence group 2301 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712867)[0m WARNING 06-04 03:05:49 scheduler.py:1484] Sequence group 2301 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:16 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:456336.000 - global_seqlen/max:522407.000 - global_seqlen/minmax_diff:66071.000 - global_seqlen/balanced_min:489790.000 - global_seqlen/balanced_max:489791.000 - global_seqlen/mean:489790.062 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.421 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.003 - actor/grad_norm:0.111 - mfu/actor:0.491 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7551.532 - response_length/max:8192.000 - response_length/min:1.000 - response_length/clip_ratio:0.881 - on_off_metrics/on_response_length_mean:7551.532 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:101.438 - prompt_length/max:302.000 - prompt_length/min:32.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:576.085 - timing_s/old_log_prob:47.841 - timing_s/adv:51.677 - timing_s/update_actor:196.148 - timing_s/step:824.157 - timing_per_token_ms/update_actor:0.025 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.074
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:17 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:484687.000 - global_seqlen/max:525893.000 - global_seqlen/minmax_diff:41206.000 - global_seqlen/balanced_min:506569.000 - global_seqlen/balanced_max:506873.000 - global_seqlen/mean:506761.688 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.481 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.003 - actor/grad_norm:0.072 - mfu/actor:0.505 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7816.065 - response_length/max:8192.000 - response_length/min:33.000 - response_length/clip_ratio:0.926 - on_off_metrics/on_response_length_mean:7816.065 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:102.086 - prompt_length/max:226.000 - prompt_length/min:36.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:606.006 - timing_s/old_log_prob:48.786 - timing_s/adv:52.715 - timing_s/update_actor:197.394 - timing_s/step:856.356 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.076
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712862)[0m MICROBATCH STEP
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712863)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:18 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:485452.000 - global_seqlen/max:525255.000 - global_seqlen/minmax_diff:39803.000 - global_seqlen/balanced_min:506463.000 - global_seqlen/balanced_max:506463.000 - global_seqlen/mean:506463.000 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.521 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.003 - actor/grad_norm:0.059 - mfu/actor:0.511 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7813.953 - response_length/max:8192.000 - response_length/min:16.000 - response_length/clip_ratio:0.920 - on_off_metrics/on_response_length_mean:7813.953 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:99.531 - prompt_length/max:282.000 - prompt_length/min:41.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:600.446 - timing_s/old_log_prob:48.063 - timing_s/adv:51.982 - timing_s/update_actor:195.356 - timing_s/step:848.014 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 03:46:55 scheduler.py:1484] Sequence group 2684 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
[36m(WorkerDict pid=712860)[0m WARNING 06-04 03:48:12 scheduler.py:1484] Sequence group 2678 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 03:48:25 scheduler.py:1484] Sequence group 2674 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 03:48:33 scheduler.py:1484] Sequence group 2670 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m WARNING 06-04 03:48:33 scheduler.py:1484] Sequence group 2670 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712862)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:19 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:498789.000 - global_seqlen/max:532384.000 - global_seqlen/minmax_diff:33595.000 - global_seqlen/balanced_min:512640.000 - global_seqlen/balanced_max:512784.000 - global_seqlen/mean:512697.875 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.549 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.002 - actor/grad_norm:0.049 - mfu/actor:0.503 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7901.053 - response_length/max:8192.000 - response_length/min:14.000 - response_length/clip_ratio:0.929 - on_off_metrics/on_response_length_mean:7901.053 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:109.852 - prompt_length/max:719.000 - prompt_length/min:45.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:602.385 - timing_s/old_log_prob:48.832 - timing_s/adv:52.676 - timing_s/update_actor:201.088 - timing_s/step:856.383 - timing_per_token_ms/update_actor:0.025 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.074
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 04:01:28 scheduler.py:1484] Sequence group 2812 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
[36m(WorkerDict pid=712865)[0m WARNING 06-04 04:01:33 scheduler.py:1484] Sequence group 2811 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712862)[0m WARNING 06-04 04:01:42 scheduler.py:1484] Sequence group 2813 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 04:02:09 scheduler.py:1484] Sequence group 2809 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m WARNING 06-04 04:02:09 scheduler.py:1484] Sequence group 2809 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 04:13:19 scheduler.py:1484] Sequence group 3055 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 04:13:46 scheduler.py:1484] Sequence group 3035 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 04:13:54 scheduler.py:1484] Sequence group 3042 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 04:14:05 scheduler.py:1484] Sequence group 3034 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 04:14:10 scheduler.py:1484] Sequence group 3035 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712862)[0m WARNING 06-04 04:14:17 scheduler.py:1484] Sequence group 3028 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 04:15:01 scheduler.py:1484] Sequence group 3003 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 04:15:45 scheduler.py:1484] Sequence group 2984 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 04:15:51 scheduler.py:1484] Sequence group 2988 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 04:16:11 scheduler.py:1484] Sequence group 2984 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 04:16:22 scheduler.py:1484] Sequence group 2981 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 04:16:31 scheduler.py:1484] Sequence group 2983 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712862)[0m WARNING 06-04 04:16:36 scheduler.py:1484] Sequence group 2977 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 04:17:56 scheduler.py:1484] Sequence group 2952 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 04:19:20 scheduler.py:1484] Sequence group 2936 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 04:19:47 scheduler.py:1484] Sequence group 2932 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 04:20:13 scheduler.py:1484] Sequence group 2927 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 04:20:42 scheduler.py:1484] Sequence group 2928 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 04:21:00 scheduler.py:1484] Sequence group 2926 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201[32m [repeated 2x across cluster][0m
[36m(main_task pid=712439)[0m Validation: Generation end.
[36m(WorkerDict pid=712863)[0m WARNING 06-04 04:21:02 scheduler.py:1484] Sequence group 2926 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201[32m [repeated 3x across cluster][0m
[36m(main_task pid=712439)[0m step:20 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:484810.000 - global_seqlen/max:530288.000 - global_seqlen/minmax_diff:45478.000 - global_seqlen/balanced_min:513361.000 - global_seqlen/balanced_max:513597.000 - global_seqlen/mean:513545.125 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.568 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.001 - actor/grad_norm:0.036 - mfu/actor:0.522 - actor/lr:0.000 - val/test_score/olympiad_bench:0.000 - val/test_score/math:0.000 - val/test_score/aime:0.000 - val/test_score/minerva:0.000 - val/test_score/amc:0.000 - avg_score:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7918.830 - response_length/max:8192.000 - response_length/min:167.000 - response_length/clip_ratio:0.938 - on_off_metrics/on_response_length_mean:7918.830 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:105.312 - prompt_length/max:324.000 - prompt_length/min:42.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:612.909 - timing_s/old_log_prob:49.173 - timing_s/adv:53.102 - timing_s/update_actor:194.091 - timing_s/testing:1168.664 - timing_s/step:2029.014 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.076
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 04:35:29 scheduler.py:1484] Sequence group 3195 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 04:37:03 scheduler.py:1484] Sequence group 3176 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m WARNING 06-04 04:37:03 scheduler.py:1484] Sequence group 3176 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712867)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:21 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:488632.000 - global_seqlen/max:522442.000 - global_seqlen/minmax_diff:33810.000 - global_seqlen/balanced_min:510397.000 - global_seqlen/balanced_max:510461.000 - global_seqlen/mean:510439.250 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.580 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.001 - actor/grad_norm:0.034 - mfu/actor:0.519 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7865.246 - response_length/max:8192.000 - response_length/min:13.000 - response_length/clip_ratio:0.928 - on_off_metrics/on_response_length_mean:7865.246 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:110.367 - prompt_length/max:488.000 - prompt_length/min:38.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:602.783 - timing_s/old_log_prob:48.575 - timing_s/adv:52.577 - timing_s/update_actor:193.845 - timing_s/step:849.459 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712865)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m 
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:22 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:495367.000 - global_seqlen/max:530573.000 - global_seqlen/minmax_diff:35206.000 - global_seqlen/balanced_min:509900.000 - global_seqlen/balanced_max:509971.000 - global_seqlen/mean:509959.750 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.592 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.001 - actor/grad_norm:0.025 - mfu/actor:0.520 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7866.832 - response_length/max:8192.000 - response_length/min:40.000 - response_length/clip_ratio:0.933 - on_off_metrics/on_response_length_mean:7866.832 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:101.289 - prompt_length/max:257.000 - prompt_length/min:45.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:606.247 - timing_s/old_log_prob:49.414 - timing_s/adv:53.376 - timing_s/update_actor:193.645 - timing_s/step:853.536 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 05:03:51 scheduler.py:1484] Sequence group 3449 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 05:04:16 scheduler.py:1484] Sequence group 3445 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 05:05:02 scheduler.py:1484] Sequence group 3439 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 05:05:24 scheduler.py:1484] Sequence group 3433 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m WARNING 06-04 05:05:24 scheduler.py:1484] Sequence group 3433 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712867)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(main_task pid=712439)[0m step:23 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:495947.000 - global_seqlen/max:526704.000 - global_seqlen/minmax_diff:30757.000 - global_seqlen/balanced_min:514282.000 - global_seqlen/balanced_max:514688.000 - global_seqlen/mean:514422.812 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.602 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.024 - mfu/actor:0.505 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7943.028 - response_length/max:8192.000 - response_length/min:133.000 - response_length/clip_ratio:0.944 - on_off_metrics/on_response_length_mean:7943.028 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:94.828 - prompt_length/max:354.000 - prompt_length/min:39.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:617.217 - timing_s/old_log_prob:48.644 - timing_s/adv:52.719 - timing_s/update_actor:200.572 - timing_s/step:870.758 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.076
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712862)[0m WARNING 06-04 05:17:49 scheduler.py:1484] Sequence group 3578 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 05:18:37 scheduler.py:1484] Sequence group 3574 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 05:19:30 scheduler.py:1484] Sequence group 3567 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m WARNING 06-04 05:19:30 scheduler.py:1484] Sequence group 3567 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:24 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:492308.000 - global_seqlen/max:531987.000 - global_seqlen/minmax_diff:39679.000 - global_seqlen/balanced_min:517644.000 - global_seqlen/balanced_max:517944.000 - global_seqlen/mean:517838.125 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.612 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.019 - mfu/actor:0.494 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7987.314 - response_length/max:8192.000 - response_length/min:36.000 - response_length/clip_ratio:0.949 - on_off_metrics/on_response_length_mean:7987.314 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:103.906 - prompt_length/max:542.000 - prompt_length/min:48.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:611.113 - timing_s/old_log_prob:49.610 - timing_s/adv:53.626 - timing_s/update_actor:206.504 - timing_s/step:871.484 - timing_per_token_ms/update_actor:0.025 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 05:32:51 scheduler.py:1484] Sequence group 3705 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 05:34:20 scheduler.py:1484] Sequence group 3688 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m WARNING 06-04 05:34:21 scheduler.py:1484] Sequence group 3691 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712867)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(main_task pid=712439)[0m step:25 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:498635.000 - global_seqlen/max:529902.000 - global_seqlen/minmax_diff:31267.000 - global_seqlen/balanced_min:513896.000 - global_seqlen/balanced_max:514039.000 - global_seqlen/mean:514018.375 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.620 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.018 - mfu/actor:0.510 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7926.826 - response_length/max:8192.000 - response_length/min:20.000 - response_length/clip_ratio:0.936 - on_off_metrics/on_response_length_mean:7926.826 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:104.711 - prompt_length/max:360.000 - prompt_length/min:34.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:601.912 - timing_s/old_log_prob:48.504 - timing_s/adv:52.509 - timing_s/update_actor:198.583 - timing_s/step:853.272 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.074
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 05:48:02 scheduler.py:1484] Sequence group 3825 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
[36m(WorkerDict pid=712866)[0m WARNING 06-04 05:48:17 scheduler.py:1484] Sequence group 3825 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712867)[0m WARNING 06-04 05:48:17 scheduler.py:1484] Sequence group 3825 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712863)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:26 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:483807.000 - global_seqlen/max:532122.000 - global_seqlen/minmax_diff:48315.000 - global_seqlen/balanced_min:513070.000 - global_seqlen/balanced_max:513187.000 - global_seqlen/mean:513116.000 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.628 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.016 - mfu/actor:0.524 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7913.578 - response_length/max:8192.000 - response_length/min:11.000 - response_length/clip_ratio:0.937 - on_off_metrics/on_response_length_mean:7913.578 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:103.859 - prompt_length/max:412.000 - prompt_length/min:39.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:616.660 - timing_s/old_log_prob:48.791 - timing_s/adv:52.715 - timing_s/update_actor:193.481 - timing_s/step:863.123 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.076
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 06:01:38 scheduler.py:1484] Sequence group 3957 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
[36m(WorkerDict pid=712862)[0m WARNING 06-04 06:01:46 scheduler.py:1484] Sequence group 3959 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 06:02:36 scheduler.py:1484] Sequence group 3947 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 06:03:05 scheduler.py:1484] Sequence group 3946 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m WARNING 06-04 06:03:05 scheduler.py:1484] Sequence group 3946 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:27 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:490781.000 - global_seqlen/max:532488.000 - global_seqlen/minmax_diff:41707.000 - global_seqlen/balanced_min:516488.000 - global_seqlen/balanced_max:517421.000 - global_seqlen/mean:516989.875 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.635 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.015 - mfu/actor:0.526 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7968.350 - response_length/max:8192.000 - response_length/min:129.000 - response_length/clip_ratio:0.953 - on_off_metrics/on_response_length_mean:7968.350 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:109.617 - prompt_length/max:291.000 - prompt_length/min:36.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:609.960 - timing_s/old_log_prob:48.821 - timing_s/adv:52.811 - timing_s/update_actor:193.941 - timing_s/step:856.955 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 06:17:25 scheduler.py:1484] Sequence group 4073 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m WARNING 06-04 06:17:25 scheduler.py:1484] Sequence group 4073 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712862)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:28 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:507753.000 - global_seqlen/max:530120.000 - global_seqlen/minmax_diff:22367.000 - global_seqlen/balanced_min:516140.000 - global_seqlen/balanced_max:516816.000 - global_seqlen/mean:516551.688 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.641 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.016 - mfu/actor:0.503 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7976.472 - response_length/max:8192.000 - response_length/min:11.000 - response_length/clip_ratio:0.949 - on_off_metrics/on_response_length_mean:7976.472 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:94.648 - prompt_length/max:229.000 - prompt_length/min:38.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:612.383 - timing_s/old_log_prob:48.312 - timing_s/adv:52.251 - timing_s/update_actor:202.809 - timing_s/step:867.682 - timing_per_token_ms/update_actor:0.025 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 06:30:27 scheduler.py:1484] Sequence group 4216 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 06:30:37 scheduler.py:1484] Sequence group 4213 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 06:30:49 scheduler.py:1484] Sequence group 4214 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712867)[0m WARNING 06-04 06:30:49 scheduler.py:1484] Sequence group 4214 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:29 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:503307.000 - global_seqlen/max:531792.000 - global_seqlen/minmax_diff:28485.000 - global_seqlen/balanced_min:516454.000 - global_seqlen/balanced_max:516928.000 - global_seqlen/mean:516730.125 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.646 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.018 - mfu/actor:0.522 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7971.064 - response_length/max:8192.000 - response_length/min:309.000 - response_length/clip_ratio:0.938 - on_off_metrics/on_response_length_mean:7971.064 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:102.844 - prompt_length/max:308.000 - prompt_length/min:34.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:599.938 - timing_s/old_log_prob:48.833 - timing_s/adv:52.807 - timing_s/update_actor:195.199 - timing_s/step:848.162 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.074
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 06:44:13 scheduler.py:1484] Sequence group 4346 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
[36m(WorkerDict pid=712862)[0m WARNING 06-04 06:44:23 scheduler.py:1484] Sequence group 4345 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 06:45:05 scheduler.py:1484] Sequence group 4339 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 06:45:15 scheduler.py:1484] Sequence group 4335 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639358, ip=30.207.98.85)[0m WARNING 06-04 06:45:15 scheduler.py:1484] Sequence group 4335 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712862)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 06:56:41 scheduler.py:1484] Sequence group 4589 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 06:56:55 scheduler.py:1484] Sequence group 4581 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 06:57:19 scheduler.py:1484] Sequence group 4569 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 06:57:30 scheduler.py:1484] Sequence group 4559 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 06:57:37 scheduler.py:1484] Sequence group 4562 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 06:58:25 scheduler.py:1484] Sequence group 4539 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 06:58:40 scheduler.py:1484] Sequence group 4531 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 06:58:46 scheduler.py:1484] Sequence group 4530 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 06:59:20 scheduler.py:1484] Sequence group 4519 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 06:59:41 scheduler.py:1484] Sequence group 4508 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 06:59:50 scheduler.py:1484] Sequence group 4510 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 07:01:27 scheduler.py:1484] Sequence group 4487 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 07:01:40 scheduler.py:1484] Sequence group 4480 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 07:01:54 scheduler.py:1484] Sequence group 4478 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 07:02:56 scheduler.py:1484] Sequence group 4468 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=712862)[0m WARNING 06-04 07:03:07 scheduler.py:1484] Sequence group 4462 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 07:03:39 scheduler.py:1484] Sequence group 4457 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 07:03:55 scheduler.py:1484] Sequence group 4457 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501[32m [repeated 2x across cluster][0m
[36m(main_task pid=712439)[0m Validation: Generation end.
[36m(WorkerDict pid=712864)[0m WARNING 06-04 07:03:55 scheduler.py:1484] Sequence group 4457 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
[36m(main_task pid=712439)[0m step:30 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:499955.000 - global_seqlen/max:528055.000 - global_seqlen/minmax_diff:28100.000 - global_seqlen/balanced_min:515585.000 - global_seqlen/balanced_max:516504.000 - global_seqlen/mean:516081.750 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.651 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.013 - mfu/actor:0.507 - actor/lr:0.000 - val/test_score/amc:0.000 - val/test_score/aime:0.000 - val/test_score/minerva:0.000 - val/test_score/math:0.000 - val/test_score/olympiad_bench:0.000 - avg_score:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7960.605 - response_length/max:8192.000 - response_length/min:67.000 - response_length/clip_ratio:0.950 - on_off_metrics/on_response_length_mean:7960.605 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:103.172 - prompt_length/max:368.000 - prompt_length/min:44.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:618.031 - timing_s/old_log_prob:48.892 - timing_s/adv:52.863 - timing_s/update_actor:200.874 - timing_s/testing:1189.621 - timing_s/step:2061.629 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.076
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712867)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(main_task pid=712439)[0m step:31 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:508762.000 - global_seqlen/max:529559.000 - global_seqlen/minmax_diff:20797.000 - global_seqlen/balanced_min:519261.000 - global_seqlen/balanced_max:520330.000 - global_seqlen/mean:519894.875 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.656 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.001 - actor/grad_norm:0.023 - mfu/actor:0.515 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:8031.154 - response_length/max:8192.000 - response_length/min:333.000 - response_length/clip_ratio:0.965 - on_off_metrics/on_response_length_mean:8031.154 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:92.203 - prompt_length/max:200.000 - prompt_length/min:39.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:605.668 - timing_s/old_log_prob:48.716 - timing_s/adv:52.902 - timing_s/update_actor:199.370 - timing_s/step:858.175 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.074
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 07:33:09 scheduler.py:1484] Sequence group 4854 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 07:33:43 scheduler.py:1484] Sequence group 4852 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 07:33:50 scheduler.py:1484] Sequence group 4850 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m WARNING 06-04 07:33:54 scheduler.py:1484] Sequence group 4850 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712865)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:32 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:504160.000 - global_seqlen/max:530716.000 - global_seqlen/minmax_diff:26556.000 - global_seqlen/balanced_min:516742.000 - global_seqlen/balanced_max:517771.000 - global_seqlen/mean:517471.188 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.660 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.021 - mfu/actor:0.521 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7987.526 - response_length/max:8192.000 - response_length/min:31.000 - response_length/clip_ratio:0.944 - on_off_metrics/on_response_length_mean:7987.526 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:97.961 - prompt_length/max:288.000 - prompt_length/min:34.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:611.943 - timing_s/old_log_prob:49.190 - timing_s/adv:53.174 - timing_s/update_actor:196.114 - timing_s/step:861.486 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 07:47:19 scheduler.py:1484] Sequence group 4982 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
[36m(WorkerDict pid=712862)[0m WARNING 06-04 07:47:33 scheduler.py:1484] Sequence group 4984 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 07:47:39 scheduler.py:1484] Sequence group 4981 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 07:47:58 scheduler.py:1484] Sequence group 4977 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m WARNING 06-04 07:47:58 scheduler.py:1484] Sequence group 4977 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712867)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712862)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:33 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:504242.000 - global_seqlen/max:531696.000 - global_seqlen/minmax_diff:27454.000 - global_seqlen/balanced_min:517375.000 - global_seqlen/balanced_max:518137.000 - global_seqlen/mean:517786.500 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.664 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.001 - actor/grad_norm:0.017 - mfu/actor:0.515 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7985.234 - response_length/max:8192.000 - response_length/min:68.000 - response_length/clip_ratio:0.952 - on_off_metrics/on_response_length_mean:7985.234 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:105.180 - prompt_length/max:439.000 - prompt_length/min:40.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:614.565 - timing_s/old_log_prob:49.953 - timing_s/adv:54.040 - timing_s/update_actor:198.531 - timing_s/step:867.373 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.007 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712862)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712865)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:34 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:507284.000 - global_seqlen/max:531255.000 - global_seqlen/minmax_diff:23971.000 - global_seqlen/balanced_min:519739.000 - global_seqlen/balanced_max:520371.000 - global_seqlen/mean:519965.438 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.668 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.013 - mfu/actor:0.531 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:8026.101 - response_length/max:8192.000 - response_length/min:170.000 - response_length/clip_ratio:0.957 - on_off_metrics/on_response_length_mean:8026.101 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:98.359 - prompt_length/max:310.000 - prompt_length/min:38.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:609.655 - timing_s/old_log_prob:49.162 - timing_s/adv:53.158 - timing_s/update_actor:193.299 - timing_s/step:856.360 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.074
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 08:15:58 scheduler.py:1484] Sequence group 5240 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 08:16:18 scheduler.py:1484] Sequence group 5236 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 08:16:44 scheduler.py:1484] Sequence group 5229 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 08:16:49 scheduler.py:1484] Sequence group 5233 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 08:17:06 scheduler.py:1484] Sequence group 5230 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712862)[0m WARNING 06-04 08:17:42 scheduler.py:1484] Sequence group 5228 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712863)[0m WARNING 06-04 08:17:42 scheduler.py:1484] Sequence group 5228 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712862)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m 
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712862)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:35 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:512512.000 - global_seqlen/max:530176.000 - global_seqlen/minmax_diff:17664.000 - global_seqlen/balanced_min:520802.000 - global_seqlen/balanced_max:521299.000 - global_seqlen/mean:521082.500 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.672 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.011 - mfu/actor:0.531 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:8038.953 - response_length/max:8192.000 - response_length/min:106.000 - response_length/clip_ratio:0.960 - on_off_metrics/on_response_length_mean:8038.953 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:102.961 - prompt_length/max:309.000 - prompt_length/min:33.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:602.660 - timing_s/old_log_prob:48.734 - timing_s/adv:52.720 - timing_s/update_actor:193.654 - timing_s/step:849.272 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.073
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 08:30:06 scheduler.py:1484] Sequence group 5369 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m WARNING 06-04 08:30:06 scheduler.py:1484] Sequence group 5369 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712867)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m 
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712866)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:36 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:502466.000 - global_seqlen/max:535654.000 - global_seqlen/minmax_diff:33188.000 - global_seqlen/balanced_min:518427.000 - global_seqlen/balanced_max:518958.000 - global_seqlen/mean:518714.312 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.676 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.011 - mfu/actor:0.535 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:7999.771 - response_length/max:8192.000 - response_length/min:216.000 - response_length/clip_ratio:0.954 - on_off_metrics/on_response_length_mean:7999.771 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:105.141 - prompt_length/max:929.000 - prompt_length/min:36.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:616.446 - timing_s/old_log_prob:48.914 - timing_s/adv:53.078 - timing_s/update_actor:191.602 - timing_s/step:861.386 - timing_per_token_ms/update_actor:0.023 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 08:45:34 scheduler.py:1484] Sequence group 5482 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
[36m(WorkerDict pid=712860)[0m WARNING 06-04 08:45:48 scheduler.py:1484] Sequence group 5487 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 08:46:05 scheduler.py:1484] Sequence group 5482 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712867)[0m WARNING 06-04 08:46:05 scheduler.py:1484] Sequence group 5482 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(main_task pid=712439)[0m step:37 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:491112.000 - global_seqlen/max:531270.000 - global_seqlen/minmax_diff:40158.000 - global_seqlen/balanced_min:518251.000 - global_seqlen/balanced_max:519552.000 - global_seqlen/mean:519005.812 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.679 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.010 - mfu/actor:0.523 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:8010.708 - response_length/max:8192.000 - response_length/min:25.000 - response_length/clip_ratio:0.955 - on_off_metrics/on_response_length_mean:8010.708 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:98.758 - prompt_length/max:260.000 - prompt_length/min:41.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:606.041 - timing_s/old_log_prob:49.787 - timing_s/adv:53.899 - timing_s/update_actor:195.677 - timing_s/step:855.887 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.074
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 08:59:26 scheduler.py:1484] Sequence group 5621 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
[36m(WorkerDict pid=712862)[0m WARNING 06-04 09:00:44 scheduler.py:1484] Sequence group 5612 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 09:00:55 scheduler.py:1484] Sequence group 5606 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m WARNING 06-04 09:00:55 scheduler.py:1484] Sequence group 5606 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:38 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:503859.000 - global_seqlen/max:530544.000 - global_seqlen/minmax_diff:26685.000 - global_seqlen/balanced_min:518081.000 - global_seqlen/balanced_max:519778.000 - global_seqlen/mean:519203.938 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.682 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.009 - mfu/actor:0.521 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:8016.272 - response_length/max:8192.000 - response_length/min:82.000 - response_length/clip_ratio:0.958 - on_off_metrics/on_response_length_mean:8016.272 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:96.289 - prompt_length/max:261.000 - prompt_length/min:32.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:626.837 - timing_s/old_log_prob:49.493 - timing_s/adv:53.588 - timing_s/update_actor:196.741 - timing_s/step:877.439 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.076
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712863)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639360, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(main_task pid=712439)[0m step:39 - batch/avg_prefix_ratio:0.000 - batch/solve_none:128.000 - batch/solve_none_format:0.000 - batch/solve_all:0.000 - batch/solved:0.000 - batch/failed:1.000 - batch/on_solved:0.000 - batch/off_solved:0.000 - critic/kl:0.000 - critic/kl_coeff:0.000 - global_seqlen/min:503847.000 - global_seqlen/max:531402.000 - global_seqlen/minmax_diff:27555.000 - global_seqlen/balanced_min:520798.000 - global_seqlen/balanced_max:520888.000 - global_seqlen/mean:520836.312 - actor/off_pg_loss:0.000 - actor/on_pg_loss:0.000 - actor/off_pg_clipfrac:0.000 - actor/off_policy_prob:0.000 - actor/on_policy_prob:0.000 - actor/off_ratio_mean:0.000 - actor/off_ratio_max_clip_frac:0.000 - actor/off_ratio_min_clip_frac:0.000 - actor/entropy_loss:11.685 - actor/pg_loss:0.000 - actor/pg_clipfrac:0.000 - actor/ppo_kl:0.000 - actor/grad_norm:0.009 - mfu/actor:0.521 - actor/lr:0.000 - critic/score/mean:0.000 - critic/score/max:0.000 - critic/score/min:0.000 - critic/rewards/mean:0.000 - critic/rewards/max:0.000 - critic/rewards/min:0.000 - critic/advantages/mean:0.000 - critic/advantages/max:0.000 - critic/advantages/min:0.000 - critic/returns/mean:0.000 - critic/returns/max:0.000 - critic/returns/min:0.000 - response_length/mean:8024.981 - response_length/max:8192.000 - response_length/min:219.000 - response_length/clip_ratio:0.963 - on_off_metrics/on_response_length_mean:8024.981 - on_off_metrics/off_response_length_mean:nan - on_off_metrics/on_score:0.000 - on_off_metrics/off_score:nan - on_off_metrics/off_on_example_ratio:0.000 - prompt_length/mean:113.086 - prompt_length/max:793.000 - prompt_length/min:38.000 - prompt_length/clip_ratio:0.000 - timing_s/gen:614.623 - timing_s/old_log_prob:48.929 - timing_s/adv:53.067 - timing_s/update_actor:197.311 - timing_s/step:865.259 - timing_per_token_ms/update_actor:0.024 - timing_per_token_ms/adv:0.006 - timing_per_token_ms/gen:0.075
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 09:28:07 scheduler.py:1484] Sequence group 5877 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 09:28:17 scheduler.py:1484] Sequence group 5877 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712866)[0m WARNING 06-04 09:28:24 scheduler.py:1484] Sequence group 5876 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 09:29:13 scheduler.py:1484] Sequence group 5867 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m WARNING 06-04 09:29:16 scheduler.py:1484] Sequence group 5867 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712862)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712861)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m MICROBATCH STEP
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712864)[0m MICROBATCH STEP[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=639354, ip=30.207.98.85)[0m no token mean: mean normalization 8192
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=712861)[0m MICROBATCH STEP
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712864)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=712860)[0m MICROBATCH STEP[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 09:39:36 scheduler.py:1484] Sequence group 6135 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m no token mean: mean normalization 8192[32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=639356, ip=30.207.98.85)[0m MICROBATCH STEP[32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 09:39:50 scheduler.py:1484] Sequence group 6127 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 09:40:36 scheduler.py:1484] Sequence group 6099 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 09:40:41 scheduler.py:1484] Sequence group 6101 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 09:40:56 scheduler.py:1484] Sequence group 6090 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639357, ip=30.207.98.85)[0m WARNING 06-04 09:41:04 scheduler.py:1484] Sequence group 6085 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712865)[0m WARNING 06-04 09:41:24 scheduler.py:1484] Sequence group 6076 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=639359, ip=30.207.98.85)[0m WARNING 06-04 09:42:36 scheduler.py:1484] Sequence group 6048 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=712860)[0m WARNING 06-04 09:42:45 scheduler.py:1484] Sequence group 6050 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=639163, ip=30.207.98.85)[0m WARNING 06-04 09:43:06 scheduler.py:1484] Sequence group 6040 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=639355, ip=30.207.98.85)[0m WARNING 06-04 09:43:18 scheduler.py:1484] Sequence group 6040 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=712862)[0m WARNING 06-04 09:43:55 scheduler.py:1484] Sequence group 6029 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801[32m [repeated 4x across cluster][0m
